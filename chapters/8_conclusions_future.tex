\section{Summary}

\emph{In-situ} Data Exploration is an active research area that requires
a multidisciplinary approach: algorithms, data structures, machine learning,
statistics,  data visualization, information sciences, and the domain knowledge
--- or business understanding ---  provided by an expert.

Going back to the \gls{CRISPDM} model described in  chapter~\ref{chapter:introduction}
and shown in figure~\ref{fig:crispdm}, our initial objective was to identify
gaps in the tooling available for experts to understand data coming as a set of
unprocessed and perhaps inconsistent sets of files. These files are not optimized
for access, and any early decision on how to ingest them into a database may be
counterproductive until the dataset is better understood.

The literature survey from chapter~\ref{chapter:literature_review} showed that
solutions for visualization, optimizations, indexing and physical layout abound.
Still, there is little to no mention of assisting users on \emph{understanding}
data schema, especially when it comes to multiple files from diverse origins or
when meta-data is incomplete or inconsistent.
In chapter~\ref{chapter:diverse}, we confirmed that users spend a non-negligible
amount of resources just examining the data structure and layout.

The question that followed was: can we leverage the data \emph{distribution} to
assist users in understanding the schema, on seeing how different datasets may come together?
This is particularly important when the data is numerical and uncertain since
one can not just compare tuples individually but needs to inspect distributions.
In the relational world, the \gls{IND} concept comes close to the objective:
Parts of a relation contained (included) within another. However, this modeling
relies on the attributes' discrete nature, such as name, date of birth, etc.

In chapter~\ref{chapter:presq} we propose a generalization, the \gls{EDD}, that
relaxes the strict containment relation required by \glspl{IND}.
We then introduce \PresQ, a novel algorithm for \gls{EDD} finding that incorporates
uncertainty into its world modeling, proving that relying on data distribution alone is feasible.
Therefore, \PresQ is applicable in situations where most existing \gls{IND} solutions
are not: when the data is intrinsically uncertain --- measures of physical properties ---,
or when the validation strategy for the inclusion is an approximate heuristic.
The only requirement is that the expectation of false negatives --- i.e., significance
level for statistical tests --- can be estimated.

For the experiments used to evaluate \PresQ, described in ~\ref{sec:presq_experiments},
the statistical test of choice was based on \gls{kNN}. While this test
performs well for many datasets, the resulting trained model can not be easily reused.
In chapter~\ref{chapter:som}, we introduce a statistical test based on \gls{SOM}, which provides,
in addition to a $p$ value, a trained projection that we can later use for binning and
cross-matching both datasets using the matching set of features. The resulting \gls{SOM}
is also interpretable in case of rejection, which is also helpful in tentative data exploration.

\section{Contributions}

We summarize here the main contributions of this thesis:

\subsection{Survey of state of the art}
Idreos \etal surveyed the state of the art of \gls{IDE} up to the first half of 2015~\cite{Idreos2015}.
Being an active research area, we performed an exhaustive systematic literature mapping up to mid-2017.
Almost 60\% of the classified works were published in 2015 and later. The results
of this survey, presented in chapter~\ref{chapter:literature_review}, are a valuable update on
the state-of-the-art.

\subsection{New category for Interactive Data Exploration}

The state of the literature at the time of our survey indicated that, within the
\gls{IDE} research community, querying datasets split over multiple files is
neglected~\cite{Silva2016}. One could argue that the logical file containing a given
subset of the data is a detail that can be integrated into an existing index. This is
true as long as the data layout is similar, but this is not always the case.
We proposed a new category within the \emph{Middleware Layer}: \emph{Schema Homogenization}.
A new set of articles has been classified under this category in table~\ref{tab:missing_middleware}.

\subsection{Definition of \glsentrylong{EDD}}
In section \ref{sec:edd}, we introduced the concept of \glsxtrlong{EDD}, expanding
the family of data dependencies to four types~\cite{abedjan2015}. We
summarize the classification in table~\ref{tab:family_dependencies}.
Note that \gls{EDD} are, by definition, approximate.

\begin{table}[htb]
\centering
\begin{tabular}{ll}
\rowcolor[HTML]{EFEFEF} 
\cellcolor[HTML]{EFEFEF}                                          & Key Discovery         \\
\rowcolor[HTML]{EFEFEF} 
\cellcolor[HTML]{EFEFEF}                                          & Conditional           \\
\rowcolor[HTML]{EFEFEF} 
\multirow{-3}{*}{\cellcolor[HTML]{EFEFEF}Uniqueness}              & (Approximate)         \\
                                                                  & Foreign key discovery \\
                                                                  & Conditional           \\
\multirow{-3}{*}{\glsxtrlong{IND}}                                & (Approximate)         \\
\rowcolor[HTML]{EFEFEF} 
\cellcolor[HTML]{EFEFEF}                                          & Conditional           \\
\rowcolor[HTML]{EFEFEF} 
\multirow{-2}{*}{\cellcolor[HTML]{EFEFEF}Functional Dependencies} & (Approximate)         \\
\glsxtrlong{EDD}                                  & (Approximate)        
\end{tabular}
\caption{Classification of dependency detection tasks.}
\label{tab:family_dependencies}
\end{table}

\subsection{Algorithms}

Querying data split across multiple files with similar schemas is another active
area of research within the \emph{Relational Algebra} domain. However, existing solutions
do not work over attributes defined in the real domain.

In chapter~\ref{chapter:presq} we presented \PresQ, an algorithm for finding quasi-cliques
on uniform hypergraphs that can be used to find sets of attributes \gls{EDD}
between datasets. \PresQ is not limited to \gls{EDD} finding and can potentially be
of use to other areas that have a strong combinatorial aspect, such as
chemistry or biology~\cite{Bretto2013}.

In chapter~\ref{chapter:som}, we introduced a two-sample multivariate statistical test based on
\glspl{SOM} with a performance comparable to tests based on machine learning models. An additional advantage
of this technique is that it outputs an interpretable projection of the two samples. It can be used
by itself or in conjunction with \PresQ.

\subsection{Publications}

The contributions from this thesis have been published in the following
papers:

\begin{refsection}
\nocite{Alvarez2019,Alvarez2021inference,AlvarezAyllonPresQ2022,Alvarez2022SOM}

\printbibliography[heading=none]
\end{refsection}

\subsection{Software}

The software generated and used in our tests are archived and publicly
available in Zenodo:

\begin{refsection}
\nocite{PresQ,SOMA}

\printbibliography[heading=none]
\end{refsection}

\section{Future work}

Finally, we enumerate some interesting research paths that can further improve
the current state of the art, adding valuable algorithms to the tool-sets
available for data scientists:

\begin{itemize}
    \item In chapter~\ref{chapter:presq}, we prove that finding quasi-cliques in hypergraphs
    is a successful technique to find \gls{EDD} or \gls{IND} based on approximate heuristics
    between relations. Therefore, a place for further research is to
    \textbf{improve the quasi-clique finding} algorithm, either via novel algorithms or by
    generalizing some of the many existing techniques~\cite{WU2015693}.
            
    \item On the other hand, the existing algorithms based on clique and quasi-clique search
    decouple the data --- only used during validation -- from the candidate generation.
    An interesting research strategy can be making clique and quasi-clique finding algorithms \textbf{data-aware},
    leveraging data features during the generation of candidates.
    
    \item Sometimes, the algorithms should not assume equality of distribution. For instance, one of the
    datasets may have been filtered beforehand --- i.e., signal-to-noise, value clipping, etc. This issue affects
    both \gls{EDD} and \gls{IND} algorithms~\cite{koeller2003discovery}. \textbf{Partial inclusion/equality-of-distribution}
    remains an open problem.
            
    \item \PresQ is based on frequentist probability, which does not allow incorporating \textbf{prior beliefs}
    into the algorithm. i.e., a \textbf{domain-expert} has no way of influencing the result based
    on her knowledge of the area.
    A Bayesian framework could prove helpful in this respect. Furthermore,
    it can also be used to perform local null hypothesis testing~\cite{soriano2015bayesian}, which could help
    identify partial \glspl{EDD} --- as when a filter has been applied to one of the datasets.
    
    \item Searching for quasi-cliques involves exponential time complexity on the number of nodes.
    Thus, applying a \textbf{dimensionality reduction} would reduce the total
    run-time and decrease the noise. Nonetheless, a complication arises because
    we do not know which attributes are shared.
        
    \item Finally, \textbf{multidimensional \emph{complementarity}} is another interesting
    area for further research. For instance, a single dataset may be split between multiple files
    based on the values from a given set of attributes (i.e., coordinates), which may or may not overlap.
    Combining complementary datasets would be a powerful addition to \gls{EDD} finding.
\end{itemize}

